# Backend - Documentation

## ğŸ“‹ Vue d'ensemble

Backend Node.js avec Express pour une plateforme d'analytics e-commerce Big Data. L'application fournit des API REST pour la gestion des logs, l'analyse de donnÃ©es via Elasticsearch, et le stockage de mÃ©tadonnÃ©es dans MongoDB avec cache Redis.

## ğŸ—ï¸ Architecture

### Structure des dossiers

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/              # Configuration des services
â”‚   â”‚   â”œâ”€â”€ mongodb.js       # Connexion MongoDB avec Mongoose
â”‚   â”‚   â”œâ”€â”€ elasticsearch.js # Client Elasticsearch
â”‚   â”‚   â””â”€â”€ redis.js         # Client Redis avec retry strategy
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # SchÃ©mas Mongoose
â”‚   â”‚   â”œâ”€â”€ Transaction.js   # ModÃ¨le des transactions
â”‚   â”‚   â”œâ”€â”€ FileUpload.js    # MÃ©tadonnÃ©es des fichiers uploadÃ©s
â”‚   â”‚   â””â”€â”€ SearchHistory.js # Historique des recherches
â”‚   â”‚
â”‚   â”œâ”€â”€ services/            # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ analyticsService.js      # Analytics avec cache Redis
â”‚   â”‚   â”œâ”€â”€ uploadService.js         # Gestion des uploads
â”‚   â”‚   â””â”€â”€ elasticsearchService.js  # RequÃªtes Elasticsearch
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/         # Gestionnaires de routes
â”‚   â”‚   â”œâ”€â”€ analyticsController.js
â”‚   â”‚   â”œâ”€â”€ uploadController.js
â”‚   â”‚   â”œâ”€â”€ searchController.js
â”‚   â”‚   â””â”€â”€ statsController.js
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/              # DÃ©finition des routes
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ analyticsRoutes.js
â”‚   â”‚   â”œâ”€â”€ uploadRoutes.js
â”‚   â”‚   â”œâ”€â”€ searchRoutes.js
â”‚   â”‚   â””â”€â”€ statsRoutes.js
â”‚   â”‚
â”‚   â”œâ”€â”€ middlewares/         # Middlewares Express
â”‚   â”‚   â”œâ”€â”€ errorHandler.js    # Gestion centralisÃ©e des erreurs
â”‚   â”‚   â”œâ”€â”€ requestLogger.js   # Logger de requÃªtes HTTP
â”‚   â”‚   â””â”€â”€ upload.js          # Configuration Multer
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/               # Utilitaires
â”‚   â”‚   â””â”€â”€ logger.js          # Logger personnalisÃ©
â”‚   â”‚
â”‚   â””â”€â”€ index.js             # Point d'entrÃ©e du serveur
â”‚
â”œâ”€â”€ .env                     # Variables d'environnement
â”œâ”€â”€ .env.example             # Exemple de configuration
â”œâ”€â”€ package.json             # DÃ©pendances npm
â””â”€â”€ README.md                # Ce fichier
```

## ğŸš€ DÃ©marrage

### PrÃ©requis

- Node.js 18+
- Docker Desktop (pour MongoDB, Redis, Elasticsearch)
- npm ou yarn

### Installation

```bash
cd backend
npm install
```

### Configuration

Copier `.env.example` vers `.env` et configurer les variables :

```env
PORT=3001
NODE_ENV=development

MONGODB_URI=mongodb://admin:admin123@localhost:27017/ecommerce?authSource=admin
ELASTICSEARCH_NODE=http://localhost:9200
REDIS_HOST=localhost
REDIS_PORT=6379
```

### DÃ©marrage

```bash
# Mode dÃ©veloppement (avec nodemon)
npm run dev

# Mode production
npm start
```

Le serveur dÃ©marre sur **http://localhost:3001**

## ğŸ“¡ API Endpoints

### SantÃ© de l'API

#### GET /api/health
VÃ©rifier l'Ã©tat du serveur.

**RÃ©ponse :**
```json
{
  "success": true,
  "message": "API is running",
  "timestamp": "2025-12-13T21:00:00.000Z"
}
```

---

### Analytics

#### GET /api/analytics/stats
Statistiques gÃ©nÃ©rales des transactions (avec cache Redis 5min).

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "totalAmount": 458920.50,
    "avgAmount": 152.30,
    "count": 3012
  }
}
```

#### GET /api/analytics/search?q=query
Recherche de transactions dans Elasticsearch.

**ParamÃ¨tres :**
- `q` (string) : Terme de recherche
- `page` (number) : Page (dÃ©faut: 1)
- `limit` (number) : Ã‰lÃ©ments par page (dÃ©faut: 10)

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "total": 156,
    "transactions": [...]
  }
}
```

#### GET /api/analytics/user/:userId
Analyse du comportement d'un utilisateur (avec cache Redis 10min).

#### GET /api/analytics/transactions
Liste paginÃ©e des transactions depuis MongoDB.

#### POST /api/analytics/transactions
CrÃ©er une nouvelle transaction.

**Body :**
```json
{
  "transactionId": "TRX-12345",
  "userId": "user123",
  "productId": "prod456",
  "amount": 99.99,
  "status": "completed"
}
```

---

### Upload de fichiers

#### POST /api/upload
Upload un fichier CSV/NDJSON/JSON vers le dossier surveillÃ© par Logstash.

**Form-data :**
- `file` : Fichier (max 100MB)

**Extensions autorisÃ©es :** `.csv`, `.json`, `.ndjson`

**RÃ©ponse :**
```json
{
  "success": true,
  "message": "Fichier uploadÃ© avec succÃ¨s",
  "data": {
    "id": "675c...",
    "filename": "transactions_1702492800000.csv",
    "size": 1048576,
    "fileType": "csv",
    "logType": "transaction",
    "status": "pending",
    "uploadDate": "2025-12-13T21:00:00.000Z"
  }
}
```

**DÃ©tection automatique du logType :**
- Nom contient "transaction" â†’ `transaction`
- Nom contient "error" â†’ `error`
- Nom contient "fraud" â†’ `fraud`
- Nom contient "performance" â†’ `performance`
- Nom contient "behavior" â†’ `behavior`

#### GET /api/upload/files
Liste paginÃ©e des fichiers uploadÃ©s.

**ParamÃ¨tres :**
- `page` (number) : Page
- `limit` (number) : Taille (max 100)
- `status` (string) : Filtre par statut (pending/processed/error)
- `logType` (string) : Filtre par type
- `sortBy` (string) : Champ de tri (dÃ©faut: uploadDate)
- `sortOrder` (string) : Ordre (asc/desc)

**RÃ©ponse :**
```json
{
  "success": true,
  "data": [...],
  "pagination": {
    "total": 45,
    "page": 1,
    "limit": 20,
    "totalPages": 3,
    "hasNextPage": true,
    "hasPrevPage": false
  }
}
```

#### GET /api/upload/history
Historique des uploads (limite 50).

#### GET /api/upload/:id
DÃ©tails d'un upload spÃ©cifique.

---

### Recherche dans les logs

#### GET /api/search
Recherche avancÃ©e dans Elasticsearch avec sauvegarde de l'historique.

**ParamÃ¨tres :**
- `query` (string) : Texte Ã  rechercher (dÃ©faut: *)
- `dateFrom` (ISO date) : Date de dÃ©but
- `dateTo` (ISO date) : Date de fin
- `level` (string) : Niveau de log
- `service` (string) : Service
- `logType` (string) : Type de log
- `status` (string) : Statut
- `page` (number) : Page (dÃ©faut: 1)
- `size` (number) : Taille (max 100, dÃ©faut: 20)
- `sortBy` (string) : Champ de tri (dÃ©faut: timestamp)
- `sortOrder` (string) : Ordre (asc/desc)

**Exemple :**
```
GET /api/search?query=error&dateFrom=2025-12-01&status=failed&page=1&size=20
```

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "results": [...],
    "total": 156,
    "pagination": {
      "page": 1,
      "size": 20,
      "totalPages": 8,
      "hasNextPage": true,
      "hasPrevPage": false
    },
    "executionTime": "145ms",
    "filters": {
      "query": "error",
      "dateFrom": "2025-12-01",
      "status": "failed"
    }
  }
}
```

#### GET /api/search/history
Historique des recherches effectuÃ©es.

**ParamÃ¨tres :**
- `limit` (number) : Nombre de rÃ©sultats (dÃ©faut: 50)
- `page` (number) : Page

#### GET /api/search/popular
Top 10 des recherches les plus populaires.

#### GET /api/search/stats
Statistiques globales Elasticsearch.

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "totalDocuments": 3156,
    "byIndex": [...],
    "byStatus": [...],
    "transactions": {
      "total": 458920.50,
      "average": 152.30,
      "max": 9999.99,
      "min": 0.01
    },
    "errorsCount": 234,
    "fraudCount": 12,
    "dateRange": {...}
  }
}
```

#### GET /api/search/timeline
Logs groupÃ©s par intervalle de temps.

**ParamÃ¨tres :**
- `dateFrom` (ISO date)
- `dateTo` (ISO date)
- `interval` (string) : 1h, 1d, 1w (dÃ©faut: 1h)

#### GET /api/search/log/:id
DÃ©tails d'un log spÃ©cifique par ID.

**ParamÃ¨tres optionnels :**
- `index` (string) : Nom de l'index

---

### Statistiques

#### GET /api/stats
**Statistiques dashboard avec cache Redis (60s)** - FormatÃ© pour Chart.js.

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "summary": {
      "totalLogs": 3156,
      "logsToday": 245,
      "errorsToday": 12,
      "errorRate": "4.90"
    },
    "charts": {
      "hourly": {
        "labels": ["2025-12-13 00:00", "2025-12-13 01:00", ...],
        "datasets": [{
          "label": "Logs par heure",
          "data": [45, 67, 89, ...],
          "backgroundColor": "rgba(54, 162, 235, 0.5)",
          "borderColor": "rgba(54, 162, 235, 1)",
          "borderWidth": 2,
          "fill": true
        }]
      },
      "typeDistribution": {
        "labels": ["Transactions", "Erreurs", "DÃ©tection Fraude", ...],
        "datasets": [{
          "label": "RÃ©partition par type",
          "data": [1200, 345, 89, ...],
          "backgroundColor": ["rgba(255, 99, 132, 0.7)", ...],
          "borderWidth": 2
        }]
      }
    }
  },
  "cached": false
}
```

**Utilisation avec Chart.js :**
```javascript
// Line Chart - Logs par heure
new Chart(ctx, {
  type: 'line',
  data: response.data.charts.hourly
});

// Doughnut Chart - Distribution
new Chart(ctx, {
  type: 'doughnut',
  data: response.data.charts.typeDistribution
});
```

#### GET /api/stats/detailed
Statistiques dÃ©taillÃ©es avec cache Redis (60s).

**ParamÃ¨tres :**
- `dateFrom` (ISO date) : DÃ©faut: il y a 7 jours
- `dateTo` (ISO date) : DÃ©faut: maintenant

**RÃ©ponse :**
```json
{
  "success": true,
  "data": {
    "total": 2456,
    "byStatus": [...],
    "byIndex": [...],
    "transactions": {
      "total": 458920.50,
      "average": 152.30,
      "count": 3012
    },
    "topUsers": [...],
    "dailyTrend": {
      "labels": ["2025-12-07", "2025-12-08", ...],
      "data": [234, 456, 567, ...]
    }
  },
  "cached": true
}
```

---

## ğŸ—„ï¸ ModÃ¨les de donnÃ©es

### Transaction
```javascript
{
  transactionId: String (unique, required),
  userId: String (required),
  productId: String,
  amount: Number,
  status: 'pending' | 'completed' | 'failed',
  timestamp: Date
}
```

### FileUpload
```javascript
{
  filename: String (required),
  fileType: 'csv' | 'json' | 'ndjson',
  size: Number (â‰¥0),
  uploadDate: Date,
  status: 'pending' | 'processed' | 'error',
  logType: 'transaction' | 'error' | 'fraud' | 'performance' | 'behavior',
  documentCount: Number (â‰¥0),
  errorMessage: String
}
```

**MÃ©thodes :**
- `markAsProcessed(docCount)` : Marquer comme traitÃ©
- `markAsError(errorMsg)` : Marquer comme erreur

### SearchHistory
```javascript
{
  query: String (required),
  filters: {
    dateFrom: Date,
    dateTo: Date,
    level: String,
    service: String,
    logType: String,
    status: String
  },
  pagination: {
    page: Number,
    size: Number
  },
  resultsCount: Number,
  executionTime: Number,
  userId: String,
  ipAddress: String,
  searchDate: Date
}
```

**MÃ©thodes statiques :**
- `getPopularSearches(limit)` : Top recherches

---

## ğŸ”§ Services

### analyticsService.js
- RequÃªtes Elasticsearch sur les transactions
- Cache Redis (5-10 min)
- Statistiques et recherche

### uploadService.js
- Validation fichiers (extension, taille max 100MB)
- Sauvegarde dans `ecommerce_logs/` (dossier Logstash)
- DÃ©tection automatique du type de log
- Enregistrement mÃ©tadonnÃ©es MongoDB

### elasticsearchService.js
- Client Elasticsearch centralisÃ©
- Query DSL pour recherches complexes
- Aggregations pour statistiques
- Gestion erreurs et timeouts (30s)
- 5 indices : transactions, errors, fraud, performance, user_behavior

**MÃ©thodes principales :**
- `searchLogs(filters)` : Recherche multi-critÃ¨res
- `getStats()` : Stats globales
- `getLogsByHour(options)` : Timeline
- `getLogById(id, index)` : DÃ©tails d'un log
- `getTopUsers(options)` : Top utilisateurs actifs
- `healthCheck()` : SantÃ© du cluster

---

## ğŸ›¡ï¸ Middlewares

### errorHandler.js
Gestion centralisÃ©e des erreurs avec :
- Codes HTTP appropriÃ©s
- Messages d'erreur formatÃ©s
- Stack trace en dÃ©veloppement
- Logs des erreurs

### requestLogger.js
Log de toutes les requÃªtes HTTP :
```
[INFO] [2025-12-13T21:00:00.000Z] GET /api/stats - IP: ::1
```

### upload.js (Multer)
Configuration upload :
- Stockage en mÃ©moire
- Extensions : `.csv`, `.json`, `.ndjson`
- Taille max : 100MB
- Filtrage automatique

---

## ğŸ“¦ Technologies utilisÃ©es

### Core
- **Node.js 18+** - Runtime JavaScript
- **Express 4.18** - Framework web
- **Mongoose 8.0** - ODM MongoDB

### Bases de donnÃ©es
- **MongoDB 7.0** - Base NoSQL (mÃ©tadonnÃ©es)
- **Elasticsearch 8.11** - Moteur de recherche (logs)
- **Redis 7** - Cache in-memory

### Outils
- **Multer** - Upload de fichiers
- **ioredis** - Client Redis
- **@elastic/elasticsearch** - Client Elasticsearch officiel
- **dotenv** - Gestion variables d'environnement
- **cors** - CORS middleware
- **nodemon** - Auto-reload en dev

---

## ğŸ”„ SystÃ¨me de cache

### Redis Cache Strategy

**Dashboard Stats** (`/api/stats`) :
- ClÃ© : `stats:dashboard`
- TTL : 60 secondes
- Invalidation : Automatique aprÃ¨s expiration

**Detailed Stats** (`/api/stats/detailed`) :
- ClÃ© : `stats:detailed:{timestamp_debut}:{timestamp_fin}`
- TTL : 60 secondes
- ClÃ©s uniques par plage de dates

**Analytics** :
- Transaction stats : TTL 300s (5 min)
- User behavior : TTL 600s (10 min)

**Avantages :**
- RÃ©duction du temps de rÃ©ponse : ~150ms â†’ ~2ms
- Diminution de la charge Elasticsearch
- Indicateur `cached: true/false` dans les rÃ©ponses

---

## ğŸ“Š Indices Elasticsearch

L'application interroge 5 indices :

1. **ecommerce_transactions** - Transactions e-commerce
2. **ecommerce_errors** - Logs d'erreurs
3. **ecommerce_fraud_detection** - DÃ©tection de fraudes
4. **ecommerce_performance** - MÃ©triques de performance
5. **ecommerce_user_behavior** - Comportement utilisateurs

---

## ğŸš¨ Gestion des erreurs

### Logger personnalisÃ©

4 niveaux de log :
- `info()` : Informations gÃ©nÃ©rales
- `error()` : Erreurs
- `warn()` : Avertissements
- `debug()` : Debug (uniquement en dÃ©veloppement)

Format :
```
[LEVEL] [ISO_TIMESTAMP] Message
```

### Error Handler

Toutes les erreurs passent par le middleware `errorHandler` :
- Log automatique
- RÃ©ponse JSON standardisÃ©e
- Stack trace en mode dÃ©veloppement
- Codes HTTP appropriÃ©s

---

## ğŸ” SÃ©curitÃ©

- **CORS activÃ©** : Permet les requÃªtes cross-origin
- **Validation des donnÃ©es** : Mongoose schemas
- **Taille limite** : 100MB pour uploads
- **Extensions filtrÃ©es** : Seulement CSV/JSON/NDJSON
- **Authentification MongoDB** : Credentials requis
- **Timeouts Elasticsearch** : 30s max

---

## ğŸ“ Bonnes pratiques implÃ©mentÃ©es

âœ… Architecture MVC claire et sÃ©parÃ©e  
âœ… Services rÃ©utilisables  
âœ… Gestion d'erreurs centralisÃ©e  
âœ… Logging dÃ©taillÃ©  
âœ… Cache Redis pour performance  
âœ… Validation des donnÃ©es (Mongoose)  
âœ… Code asynchrone (async/await)  
âœ… Variables d'environnement (.env)  
âœ… Pagination pour toutes les listes  
âœ… RÃ©ponses JSON standardisÃ©es  
âœ… Timeouts pour requÃªtes externes  
âœ… Retry strategy pour Redis  

---

## ğŸ› Debugging

### VÃ©rifier les connexions

```bash
# MongoDB
docker exec mongodb mongosh -u admin -p admin123 --authenticationDatabase admin --eval "db.adminCommand('ping')"

# Redis
docker exec ecommerce-redis redis-cli ping

# Elasticsearch
curl http://localhost:9200/_cluster/health
```

### Logs du serveur

Les logs s'affichent dans la console avec timestamps et niveaux.

### VÃ©rifier le cache Redis

```bash
docker exec ecommerce-redis redis-cli
> KEYS stats:*
> GET stats:dashboard
> TTL stats:dashboard
```

---

## ğŸ“ˆ Performances

- **Cache Redis** : RÃ©duction de 98% du temps de rÃ©ponse sur stats
- **Aggregations** : Elasticsearch optimisÃ© pour analytics
- **Pagination** : Max 100 Ã©lÃ©ments par page
- **Connexions** : Pool de connexions MongoDB
- **Async** : RequÃªtes parallÃ¨les quand possible

---

## ğŸ”® AmÃ©liorations futures possibles

- [ ] Authentification JWT
- [ ] Rate limiting
- [ ] Webhooks pour notifications
- [ ] Export CSV/PDF des stats
- [ ] Streaming pour gros fichiers
- [ ] Compression des rÃ©ponses (gzip)
- [ ] Monitoring (Prometheus/Grafana)
- [ ] Tests unitaires et intÃ©gration
- [ ] Documentation OpenAPI/Swagger
- [ ] CI/CD pipeline

---

## ğŸ‘¨â€ğŸ’» DÃ©veloppement

### Ajouter un nouvel endpoint

1. CrÃ©er le controller dans `src/controllers/`
2. CrÃ©er les routes dans `src/routes/`
3. Enregistrer dans `src/routes/index.js`
4. Tester avec Postman/curl

### Ajouter un nouveau modÃ¨le

1. CrÃ©er le schÃ©ma dans `src/models/`
2. Ajouter validations et mÃ©thodes
3. Utiliser dans les services/controllers

---

## ğŸ“ Support

En cas de problÃ¨me :
1. VÃ©rifier les logs du serveur
2. VÃ©rifier que Docker containers tournent
3. VÃ©rifier les variables d'environnement
4. Consulter cette documentation

---

**Version :** 1.0.0  
**DerniÃ¨re mise Ã  jour :** 13 dÃ©cembre 2025  
**Port par dÃ©faut :** 3001

# Pipeline Logstash pour fichiers JSON/NDJSON - Logs E-Commerce
# Surveille le dossier /data/json/ pour les fichiers de logs

input {
  file {
    # Surveiller le dossier JSON pour les nouveaux fichiers
    path => "/usr/share/logstash/input_data/json/*.{json,ndjson,jsonl}"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/logs/sincedb_json"
    
    # Mode de découverte des fichiers - tail surveille en continu
    mode => "tail"
    
    # Codec pour JSON - chaque ligne est un document JSON
    codec => json_lines
    
    # Tags pour identification
    tags => ["json", "logs", "ecommerce"]
    
    # Type de fichier
    type => "log_json"
  }
}

filter {
  # Gestion des erreurs de parsing JSON
  if "_jsonparsefailure" in [tags] {
    mutate {
      add_field => { 
        "parse_error" => "Failed to parse JSON"
        "original_message" => "%{message}"
      }
      add_tag => ["parse_error"]
    }
  } else {
    # Parser la date/timestamp (plusieurs formats possibles)
    if [timestamp] {
      date {
        match => [
          "timestamp", 
          "ISO8601",
          "yyyy-MM-dd HH:mm:ss",
          "yyyy-MM-dd'T'HH:mm:ss.SSSZ",
          "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'",
          "yyyy-MM-dd'T'HH:mm:ssZ",
          "UNIX",
          "UNIX_MS"
        ]
        target => "@timestamp"

      }
    } else if [@timestamp] {
      # Si @timestamp existe déjà, le garder
    } else {
      # Sinon, utiliser le temps actuel
      mutate {
        add_field => { "timestamp_missing" => true }
      }
    }
    
    # Déterminer le type de log et router vers l'index approprié
    if [logType] {
      mutate {
        lowercase => ["logType"]
      }
    } else if [type] {
      mutate {
        rename => { "type" => "logType" }
        lowercase => ["logType"]
      }
    } else if [level] {
      # Si c'est un log avec niveau (ERROR, INFO, etc.), c'est probablement un log d'erreur/application
      mutate {
        add_field => { "logType" => "application" }
      }
    } else {
      # Type par défaut
      mutate {
        add_field => { "logType" => "general" }
      }
    }
    
    # Routing selon le type de log
    if [logType] == "transaction" or [logType] == "transactions" {
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_transactions" }
      }
      
      # Conversion des types pour les transactions
      if [amount] {
        mutate {
          convert => { "amount" => "float" }
        }
      }
      if [quantity] {
        mutate {
          convert => { "quantity" => "integer" }
        }
      }
      
    } else if [logType] == "error" or [logType] == "errors" or [level] in ["ERROR", "FATAL", "CRITICAL"] {
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_errors" }
        add_tag => ["error_log"]
      }
      
      # Parser le stack trace si présent
      if [stackTrace] or [stack] or [error] {
        mutate {
          add_field => { "has_stacktrace" => true }
        }
      }
      
    } else if [logType] == "fraud" or [logType] == "fraud_detection" {
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_fraud_detection" }
        add_tag => ["fraud_detection"]
      }
      
    } else if [logType] == "performance" or [logType] == "perf" {
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_performance" }
        add_tag => ["performance_log"]
      }
      
      # Conversion des métriques de performance
      if [responseTime] {
        mutate {
          convert => { "responseTime" => "integer" }
        }
      }
      if [cpuUsage] {
        mutate {
          convert => { "cpuUsage" => "float" }
        }
      }
      if [memoryUsage] {
        mutate {
          convert => { "memoryUsage" => "float" }
        }
      }
      
    } else if [logType] == "user_behavior" or [logType] == "user" {
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_user_behavior" }
        add_tag => ["user_behavior"]
      }
    } else {
      # Index par défaut pour les logs non catégorisés
      mutate {
        add_field => { "[@metadata][index_name]" => "ecommerce_general" }
      }
    }
    
    # Enrichissement : normalisation du niveau de log
    if [level] {
      mutate {
        uppercase => ["level"]
      }
      
      # Ajouter des tags selon la sévérité
      if [level] in ["ERROR", "FATAL", "CRITICAL"] {
        mutate {
          add_tag => ["high_severity"]
        }
      } else if [level] == "WARN" or [level] == "WARNING" {
        mutate {
          add_tag => ["medium_severity"]
        }
      }
    }
    
    # Enrichissement : géolocalisation si IP présente
    if [ipAddress] or [ip] or [clientIp] {
      # Normaliser le nom du champ
      if [ip] and ![ipAddress] {
        mutate {
          rename => { "ip" => "ipAddress" }
        }
      } else if [clientIp] and ![ipAddress] {
        mutate {
          rename => { "clientIp" => "ipAddress" }
        }
      }
      
      # Géolocalisation
      if [ipAddress] and [ipAddress] != "" and [ipAddress] != "127.0.0.1" and [ipAddress] != "localhost" {
        geoip {
          source => "ipAddress"
          target => "geoip"

        }
        
        # Si la géolocalisation a réussi
        if "_geoip_lookup_failure" not in [tags] {
          mutate {
            add_field => {
              "country" => "%{[geoip][country_name]}"
              "city" => "%{[geoip][city_name]}"
            }
          }
          
          # Ajouter les coordonnées GPS si disponibles
          if [geoip][latitude] and [geoip][longitude] {
            mutate {
              add_field => {
                "location" => "%{[geoip][latitude]},%{[geoip][longitude]}"
              }
            }
          }
        }
      }
    }
    
    # Enrichissement : Parser le User Agent si présent
    if [userAgent] or [user_agent] {
      if [user_agent] and ![userAgent] {
        mutate {
          rename => { "user_agent" => "userAgent" }
        }
      }
      
      if [userAgent] and [userAgent] != "" {
        useragent {
          source => "userAgent"
          target => "ua"

        }
        
        # Extraire les infos principales
        if "_useragent_parse_failure" not in [tags] {
          mutate {
            add_field => {
              "browser" => "%{[ua][name]}"
              "browser_version" => "%{[ua][version]}"
              "os" => "%{[ua][os]}"
              "device" => "%{[ua][device]}"
            }
          }
        }
      }
    }
    
    # Enrichissement : Détection de patterns dans les messages
    if [message] {
      # Détection d'erreurs SQL
      if [message] =~ /(?i)(sql|mysql|postgres|oracle)/ and [message] =~ /(?i)(error|exception|failed)/ {
        mutate {
          add_tag => ["database_error"]
        }
      }
      
      # Détection d'erreurs réseau
      if [message] =~ /(?i)(timeout|connection|network|refused)/ {
        mutate {
          add_tag => ["network_error"]
        }
      }
      
      # Détection d'erreurs d'authentification
      if [message] =~ /(?i)(auth|unauthorized|forbidden|permission denied)/ {
        mutate {
          add_tag => ["auth_error"]
        }
      }
    }
    
    # Enrichissement : Calculer la durée si start et end time sont présents
    if [startTime] and [endTime] {
      ruby {
        code => '
          begin
            start_time = event.get("startTime")
            end_time = event.get("endTime")
            
            # Essayer de parser les timestamps
            if start_time.is_a?(String)
              start_time = Time.parse(start_time).to_f
            end
            if end_time.is_a?(String)
              end_time = Time.parse(end_time).to_f
            end
            
            duration = end_time - start_time
            event.set("duration_seconds", duration)
            event.set("duration_ms", duration * 1000)
          rescue => e
            event.tag("_duration_calculation_failed")
          end
        '
      }
    }
    
    # Enrichissement : Ajouter des métadonnées
    mutate {
      add_field => {
        "source" => "json_pipeline"
        "processed_at" => "%{@timestamp}"
      }
    }
    
    # Si un ID unique n'existe pas, en générer un
    if ![id] and ![_id] and ![documentId] {
      fingerprint {
        source => ["message", "@timestamp", "logType"]
        target => "[@metadata][fingerprint]"
        method => "SHA256"
      }
    }
  }
}

output {
  # Output vers Elasticsearch pour les logs parsés avec succès
  if "_jsonparsefailure" not in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:elasticsearch:9200}"]
      
      # Utiliser l'index déterminé dans les filtres
      index => "%{[@metadata][index_name]}-%{+YYYY.MM.dd}"
      
      # Document ID basé sur le fingerprint ou l'ID fourni
      document_id => "%{[id]}%{[_id]}%{[documentId]}%{[@metadata][fingerprint]}"
      
      # Configuration de retry
      retry_on_conflict => 5
      
      # Désactiver template pour éviter les conflits
      manage_template => false
    }
  }
  
  # Envoyer les erreurs de parsing dans un index séparé
  if "_jsonparsefailure" in [tags] or "parse_error" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:elasticsearch:9200}"]
      index => "ecommerce_parse_errors-%{+YYYY.MM.dd}"
      
      manage_template => false
    }
  }
  
  # Log pour debugging (optionnel)
  if [@metadata][debug] {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
}

